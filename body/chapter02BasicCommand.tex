\chapter{常用命令使用}
\label{sec:BasicCommand}

\input{body/commands/shortcuts}

\input{body/commands/man}

\input{body/commands/echo}

\input{body/commands/date}

\input{body/commands/yum}

% \input{body/chapter02_zypper}

\input{body/commands/parted}

\input{body/commands/mount}

\input{body/commands/grep}

\input{body/commands/crontab}

\input{body/commands/find}

\input{body/commands/top}

\input{body/commands/free}

\input{body/commands/xargs}

\input{body/commands/tr}

\input{body/commands/tar}

\input{body/commands/read}

\input{body/commands/cut}

\input{body/commands/sort}

\input{body/commands/lsof}

\section{netstat命令的使用}
\label{sec:netstatCmd}
\index{netstat}

\input{body/commands/tcpdump}

\section{traceroute命令的使用}
\label{sec:tracerouteCmd}

\input{body/commands/wget}

\input{body/commands/screen}

\input{body/commands/iptables}

\section{qperf命令的使用}
\label{sec:qperfCmd}

我们在做网络服务器的时候，通常会很关心网络的带宽和延迟。因为我们的很多
协议都是request-response协议，延迟决定了最大的QPS，而带宽决定了最大的负
荷。 通常我们知道自己的网卡是什么型号，交换机什么型号，主机之间的物理距
离是多少，理论上是知道带宽和延迟是多少的。但是现实的情况是，真正的带宽
和延迟情况会有很多变数的，比如说网卡驱动，交换机跳数，丢包率，协议栈配
置，就实际速度而言，都很大的影响了数值的估算。 所以我们需要找到工具来实
际测量下。

SUSE11sp2发行版里面自带，方便安装，专业有效，能够针对TCP和RDMA进行带宽
和延迟的详细测试。

\begin{verbatim}
# zypper install -y qperf
\end{verbatim}

由于我们需要测试Infiniband的传输速率，在安装之前请先确认安装
了InfiniBand的相关包，比如librdmacm，libibverbs等。另外，也可以选择使用
源码包编译和安装qperf，但是需要注意，在安装之前也需要将infiniband相关的
包先安装上，否则RDMA的相关测试也将无法进行。

\begin{verbatim}
# zypper install -y librdmacm libibverbs
\end{verbatim}

\subsection{参数说明及示例}

qperf分为服务器端和客户端。客户端通过发送请求并获得响应来获得服务器端和
客户端之间的网络带宽以及延迟等信息。

\begin{tabular}{lp{20em}}
  \toprule
  参数名       & 参数说明 \\
  \midrule
  <server\_ip>	& 指定服务器的地址 \\
  time            & 指定网络测试时间。默认单位为秒，单位可以通过后缀为m,h,d指定为分钟，小时，天 \\
  conf	        & 测试输出中显示本地和远端服务器和操作系统配置 \\
  use\_bits\_per\_sec & 使用b(bit)而不是B(byte)来显示网络速度 \\
  precision 2	& 设置显示小数点后几位。这里设置为显示小数点后两位 \\
  verbose\_more	& 显示更详细的配置和状态信息 \\
  loop msg\_size:1:1025k:*2 	& loop表示对指定的指标值进行轮询。这里设置为对msg\_size轮询1，2，4，8…1024k，获得对应的测试结果，下次测试的指标值是上次测试指标值的*2倍 \\
  tcp\_bw	& 对tcp的带宽进行测试 \\
  tcp\_lat	& 对tcp的延迟进行测试 \\
  udp\_bw	& 对udp的带宽进行测试 \\
  udp\_lat	& 对udp的延迟进行测试 \\
  sdp\_bw	& 对sdp的延迟进行测试 \\
  sdp\_lat	& 对sdp的延迟进行测试 \\
\bottomrule
\end{tabular}

\section{iperf命令的使用}
\label{sec:iperfCmd}

iperf工具我们主要

首先到官网获取iperf工具，并把该工具放到合适的位置。
\begin{verbatim}
# wget https://iperf.fr/download/iperf_2.0.2/iperf_2.0.2-4_amd64
# chmod +x iperf_2.0.2-4_amd64
# mv iperf_2.0.2-4_amd64 /usr/bin/iperf
\end{verbatim}

\subsection{参数说明及示例}

\begin{tabular}{lp{25em}}
  \toprule
  参数名       & 参数说明 \\
  \midrule
  --server	& 以服务端模式运行 \\
  --udp	        & 指定测试UDP，默认为TCP带宽测试 \\
  --client <host>	& 以客户端模式运行，并连接<host> \\
  --bandwidth	& 指定测试中所使用的带宽，单位为[KM]，默认为1Mbit/sec \\
  --time	        & 指定测试时间，单位为秒 \\
  --interval	& 指定多少时间间隔来报告测试结果，时间单位为秒 \\
  --format [kmKM]	& 指定报告的输出格式，单位分别为Kbits，Mbits，Kbytes，Mbytes \\
\bottomrule
\end{tabular}

\begin{enumerate}[itemsep=0pt,parsep=0pt]
\item 以太网UDP丢包率测试

\begin{verbatim}
A0304010:~ # iperf --server --udp 
A0305010:~ # iperf --udp --client 172.16.25.39 --interval 1 \
             --time 120 --bandwidth 900M
\end{verbatim}

\item InfiniBand网络UDP丢包率测试

\begin{verbatim}
# iperf --server --udp 
# iperf --udp --client 11.11.11.39 --interval 1 \
             --time 120 --bandwidth 1024M
\end{verbatim}

\item 如果不指定--udp选项，默认就是测试TCP带宽

\begin{verbatim}
A0304010:~ # iperf --server 
A0305010:~ # iperf --client 172.16.25.39  -f M
\end{verbatim}
\end{enumerate}

\section{vmstat命令的使用}
\label{sec:vmstatCmd}

Linux下vmstat输出释疑：

\begin{verbatim}
Vmstat
procs -----------memory---------- ---swap-- -----io---- --system-- ----cpu----
r b   swpd free buff cache          si so      bi bo      in cs    us sy id wa
0 0   100152 2436 97200 289740       0 1       34 45       99 33    0 0 99 0
\end{verbatim}

\begin{quote}
procs
r 列表示运行和等待cpu时间片的进程数，如果长期大于cpu个数，说明cpu不足，需要增加cpu。

b 列表示在等待资源的进程数，比如正在等待I/O、或者内存交换等。

memory
swpd 切换到内存交换区的内存数量(k表示)。如果swpd的值不为0，或者比较大，比如超过了100m，
     只要si、so的值长期为0，系统性能还是正常

free 当前的空闲页面列表中内存数量(k表示)

buff 作为buffer cache的内存数量，一般对块设备的读写才需要缓冲。

cache: 作为page cache的内存数量，一般作为文件系统的cache，如果cache较大，说明用到cache的
       文件较多，如果此时IO中bi比较小，说明文件系统效率比较好。

swap
si 由内存进入内存交换区数量。

so 由内存交换区进入内存数量。


IO
bi 从块设备读入数据的总量（读磁盘）（每秒kb）。

bo 块设备写入数据的总量（写磁盘）（每秒kb）


system 显示采集间隔内发生的中断数

in 列表示在某一时间间隔中观测到的每秒设备中断数。

cs 列表示每秒产生的上下文切换次数，如当cs比磁盘I/O和网络信息包速率高得多，都应进行进一步调查。



cpu 表示cpu的使用状态

us 列显示了用户方式下所花费 CPU 时间的百分比。us的值比较高时，说明用户进程消耗的cpu时间多，
   但是如果长期大于50\%，需要考虑优化用户的程序。

sy 列显示了内核进程所花费的cpu时间的百分比。这里us + sy的参考值为80\%，如果us+sy 大于
   80\%说明可能存在CPU不足。

wa 列显示了IO等待所占用的CPU时间的百分比。这里wa的参考值为30\%，如果wa超过30\%，说明IO等待严重，
   这可能是磁盘大量随机访问造成的，也可能磁盘或者磁盘访问控制器的带宽瓶颈造成的(主要是块操作)。

id 列显示了cpu处在空闲状态的时间百分比
\end{quote}


\section{iostat命令的使用}
\label{sec:iostatCmd}

\section{sar命令的使用}
\label{sec:sarCmd}

sar 命令行的常用格式：
\begin{verbatim}
sar [options] [-A] [-o file] t [n]
\end{verbatim}

在命令行中，n 和t 两个参数组合起来定义采样间隔和次数，t为采样间隔，是必
须有的参数，n为采样次数，是可选的，默认值是1，-o file表示将命令结果以二
进制格式存放在文件中，file 在此处不是关键字，是文件名。options 为命令行
选项，sar命令的选项很多，下面只列出常用选项：

\begin{table}[!htbp]
  \centering
  \begin{tabular}{ll}
    \toprule
    选项     & 说明 \\
    \midrule
    -A  & 所有报告的总和 \\
    -u  & CPU利用率 \\
    -v  & 进程、I节点、文件和锁表状态 \\
    -d  & 硬盘使用报告 \\
    -r  & 没有使用的内存页面和硬盘块 \\
    -g  & 串口I/O的情况(centos 5 中无此选项) \\
    -b  & 缓冲区使用情况 \\
    -a  & 文件读写情况 \\
    -c  & 系统调用情况 \\
    -R  & 进程的活动情况 \\
    -y  & 终端设备活动情况 \\
    -w  & 系统交换活动 \\
    \bottomrule
  \end{tabular}
  \caption{sar常用选项}
  \label{tab:sarOptions}
\end{table}

例一：使用命令行 sar -u t n

例如，每60秒采样一次，连续采样5次，观察CPU 的使用情况，并将采样结果以二
进制形式存入当前目录下的文件lavenliu中，需键入如下命令：

\begin{verbatim}
# sar -u -o lavenliu 60 5
SCO_SV　　　scosysv　3.2v5.0.5　i80386　　　10/01/2001
14:43:50　　　%usr　　　%sys　　%wio　　　　%idle(-u)
14:44:50　　　0　　　　　1　　　　4　　　　　　94
14:45:50　　　0　　　　　2　　　　4　　　　　　93
14:46:50　　　0　　　　　2　　　　2　　　　　　96
14:47:50　　　0　　　　　2　　　　5　　　　　　93
14:48:50　　　0　　　　　2　　　　2　　　　　　96
Average　　　 0　　　　　2　　　　4　　　　　　94
\end{verbatim}

在显示内容包括：

\begin{verbatim}
%usr：CPU处在用户模式下的时间百分比。
%sys：CPU处在系统模式下的时间百分比。
%wio：CPU等待输入输出完成时间的百分比。
%idle：CPU空闲时间百分比。
\end{verbatim}

在所有的显示中，我们应主要注意\%wio和\%idle，\%wio的值过高，表示硬盘存
在I/O瓶颈，\%idle值高，表示CPU较空闲，如果\%idle值高但系统响应慢时，有
可能是CPU等待分配内存，此时应加大内存容量。\%idle值如果持续低于10，那么
系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。

如果要查看二进制文件lavenliu中的内容，则需键入如下sar命令：

\begin{verbatim}
# sar -u -f lavenliu
\end{verbatim}

可见，sar命令即可以实时采样，又可以对以往的采样结果进行查询。

例二：使用命行sar -v t n

例如，每30秒采样一次，连续采样5次，观察核心表的状态，需键入如下命令：

\begin{verbatim}
# sar -v 30 5
SCO_SV scosysv 3.2v5.0.5 i80386 10/01/2001
10:33:23 proc-sz ov inod-sz ov file-sz ov lock-sz　　 (-v)
10:33:53  305/　321 　0　1337/2764　 0　1561/1706　0　40/　128
10:34:23  308/　321 　0　1340/2764　 0　1587/1706　0　37/　128
10:34:53　305/　321 　0　1332/2764　 0　1565/1706　0　36/　128
10:35:23　308/　321 　0　1338/2764　 0　1592/1706　0　37/　128
10:35:53　308/　321　 0　1335/2764　 0　1591/1706　0　37/　128
\end{verbatim}

显示内容包括：

\begin{quote}
proc-sz：目前核心中正在使用或分配的进程表的表项数，由核心参数MAX-PROC控制。
inod-sz：目前核心中正在使用或分配的i节点表的表项数，由核心参数MAX-INODE控制
file-sz：目前核心中正在使用或分配的文件表的表项数，由核心参数MAX-FILE控制。
ov：     溢出出现的次数。
Lock-sz：目前核心中正在使用或分配的记录加锁的表项数，由核心参数MAX-FLCKRE控制。
\end{quote}

显示格式为: 实际使用表项/可以使用的表项数

显示内容表示，核心使用完全正常，三个表没有出现溢出现象，核心参数不需调
整，如果出现溢出时，要调整相应的核心参数，将对应的表项数加大。

例三：使用命行sar -d t n

例如，每30秒采样一次，连续采样5次，报告设备使用情况，需键入如下命令：
\begin{verbatim}
# sar -d 30 5
SCO_SV scosysv 3.2v5.0.5 i80386 10/01/2001
11:06:43 device　%busy　　　avque　　　r+w/s　　blks/s　　avwait avserv (-d)
11:07:13 wd-0　　　1.47　　　2.75　　　4.67　　　14.73　　 5.50 3.14
11:07:43 wd-0　　　0.43　　　18.77　　 3.07　　　8.66　　　25.11 1.41
11:08:13 wd-0　　　0.77　　　2.78　　　2.77　　　7.26　　　4.94 2.77
11:08:43 wd-0　　　1.10　　　11.18　　 4.10　　　11.26　　 27.32 2.68
11:09:13 wd-0　　　1.97　　　21.78　　 5.86　　　34.06　　　69.66 3.35
Average wd-0　　　1.15　　　12.11　　 4.09　　　15.19　　　31.12 2.80
\end{verbatim}

显示内容包括：
\begin{verbatim}
device： sar命令正在监视的块设备的名字。
%busy： 设备忙时，传送请求所占时间的百分比。
avque： 队列站满时，未完成请求数量的平均值。
r+w/s： 每秒传送到设备或从设备传出的数据量。
blks/s： 每秒传送的块数，每块512字节。
avwait： 队列占满时传送请求等待队列空闲的平均时间。
avserv： 完成传送请求所需平均时间（毫秒）。
\end{verbatim}

在显示的内容中，wd-0是硬盘的名字，\%busy的值比较小，说明用于处理传送请求
的有效时间太少，文件系统效率不高，一般来讲，\%busy值高些，avque值低些，
文件系统的效率比较高，如果\%busy和avque值相对比较高，说明硬盘传输速度太
慢，需调整。

例四：使用命行sar -b t n

例如，每30秒采样一次，连续采样5次，报告缓冲区的使用情况，需键入如下命令：
\begin{verbatim}
# sar -b 30 5
SCO_SV scosysv 3.2v5.0.5 i80386 10/01/2001
14:54:59 bread/s lread/s %rcache bwrit/s lwrit/s %wcache pread/s pwrit/s (-b)
14:55:29　0　　147　　100　 5　　21　　78　　 0　　　0
14:55:59　0　　186　　100　 5　　25　　79　　 0　　　0
14:56:29　4　　232 　　98　 8　　58　　86　　 0　　　0
14:56:59　0　　125　　100　 5　　23　　76　　 0　　　0
14:57:29　0　　 89　　100　 4　　12　　66　　 0　　　0
Average　 1　　156 　　99　 5　　28　　80　　 0　　　0
\end{verbatim}

显示内容包括：
\begin{verbatim}
bread/s： 每秒从硬盘读入系统缓冲区buffer的物理块数。
lread/s： 平均每秒从系统buffer读出的逻辑块数。
%rcache： 在buffer cache中进行逻辑读的百分比。
bwrit/s： 平均每秒从系统buffer向磁盘所写的物理块数。
lwrit/s： 平均每秒写到系统buffer逻辑块数。
%wcache： 在buffer cache中进行逻辑读的百分比。
pread/s： 平均每秒请求物理读的次数。
pwrit/s： 平均每秒请求物理写的次数。
\end{verbatim}

在显示的内容中，最重要的是\%cache和\%wcache两列，它们的值体现着buffer的
使用效率，\%rcache的值小于90或者\%wcache的值低于65，应适当增加系
统buffer的数量，buffer数量由核心参数NBUF控制，使\%rcache达到90左
右，\%wcache达到80左右。但buffer参数值的多少影响I/O效率，增加buffer，应
在较大内存的情况下，否则系统效率反而得不到提高。

例五：使用命行sar -g t n
例如，每30秒采样一次，连续采样5次，报告串口I/O的操作情况，需键入如下命令：
\begin{verbatim}
# sar -g 30 5
SCO_SV scosysv 3.2v5.0.5 i80386　　11/22/2001
17:07:03 　ovsiohw/s　 ovsiodma/s　　ovclist/s (-g)
17:07:33　　　0.00　　　0.00　　　0.00
17:08:03　　　0.00　　　0.00　　　0.00
17:08:33　　　0.00　　　0.00　　　0.00
17:09:03　　　0.00　　　0.00　　　0.00
17:09:33　　　0.00　　　0.00　　　0.00
Average 　　　0.00　　　0.00　　　0.00
\end{verbatim}

显示内容包括：
\begin{verbatim}
ovsiohw/s：每秒在串口I/O硬件出现的溢出。
ovsiodma/s：每秒在串口I/O的直接输入输出通道高速缓存出现的溢出。
ovclist/s ：每秒字符队列出现的溢出。
\end{verbatim}

在显示的内容中，每一列的值都是零，表明在采样时间内，系统中没有发生串口
I/O溢出现象。

sar命令的用法很多，有时判断一个问题，需要几个sar命令结合起来使用，比如，
怀疑CPU存在瓶颈，可用sar -u 和sar -q来看，怀疑I/O存在瓶颈，可用sar -b、
sar -u和sar-d来看。

\input{body/commands/ip}